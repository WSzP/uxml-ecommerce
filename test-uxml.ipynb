{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csc_matrix as csc\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    roc_auc_score,\n",
    "    log_loss,\n",
    ")\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from constants import (SEED, EVENT_THRESHOLD, DEFAULT_K, DEFAULT_THRESHOLD, LOG_DIR, \n",
    "                       DATA_DIR, TEST_DATA_PATH, DATA_OCT, DATA_NOV, USECOLS, USER, ITEM, RATING, PREDICTION)\n",
    "from utilities.ms_evaluation import (rmse, auc, logloss, precision_at_k, recall_at_k, ndcg_at_k, map_at_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = r'BasicMatrixFactorization' \n",
    "Y_HAT_PATH = DATA_DIR+r'/'+NAME+r'-y_hat.npz'\n",
    "TEST_RESULTS_PATH = LOG_DIR+'\\\\'+NAME+'\\\\test-results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the matrices: (177592, 44780)\n",
      "Number of non-zero values:\n",
      "Y:  552,255\n",
      "Ŷ:  552,255\n"
     ]
    }
   ],
   "source": [
    "log = pd.Series(dtype='float64')\n",
    "y_hat = sp.load_npz(Y_HAT_PATH)\n",
    "y = sp.load_npz(TEST_DATA_PATH)\n",
    "assert y_hat.shape == y.shape, 'The shape of Y and Y_hat must match, otherwise they are not comparable.'\n",
    "print(f\"Shape of the matrices: {y.shape}\")\n",
    "print(\"Number of non-zero values:\")\n",
    "print(f\"Y: {y.nnz:8,}\")\n",
    "print(f\"Ŷ: {y_hat.nnz:8,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually, the CSC is used when there are more rows than columns. (If there are more columns, use CSR instead.)\n",
    "y_hat = y_hat.tocsc()\n",
    "y = y.tocsc()\n",
    "y_nz = np.array(y[y.nonzero()]).reshape(-1)\n",
    "y_hat_nz = np.array(y_hat[y_hat.nonzero()]).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run for the recommender engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of purchase events in test the dataset: 547912\n"
     ]
    }
   ],
   "source": [
    "input_df = pd.concat([pd.read_csv(DATA_OCT, engine='c', sep=',',usecols=USECOLS)\n",
    "                ,pd.read_csv(DATA_NOV, engine='c', sep=',',usecols=USECOLS)])\n",
    "drop_visitors = set(input_df.user_id.value_counts()[input_df.user_id.value_counts()<EVENT_THRESHOLD].index)\n",
    "input_df = input_df[~input_df.user_id.isin(drop_visitors)]\n",
    "input_df.reset_index(inplace=True,drop=True)\n",
    "new_user_id = pd.Series(pd.read_csv(DATA_DIR+r'new_user_id.csv', index_col=1, squeeze=True), dtype='int32')\n",
    "new_product_id = pd.Series(pd.read_csv(DATA_DIR+r'new_product_id.csv', index_col=1, squeeze=True), dtype='int32')\n",
    "input_df = input_df[input_df.event_type=='purchase']\n",
    "input_df = input_df.drop(columns=['event_type'])\n",
    "purchases = set()\n",
    "\n",
    "for row in input_df.itertuples(): \n",
    "    uid = new_user_id[row.user_id]\n",
    "    pid = new_product_id[row.product_id]\n",
    "    purchases.add((uid,pid))    \n",
    "print(f\"Number of purchase events in test the dataset: {len(purchases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating\n",
       "0       0       0       1\n",
       "1       0      80       1\n",
       "2       0     291       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true = []\n",
    "rows,cols = y.nonzero()\n",
    "for row,col in zip(rows,cols):\n",
    "    if (row,col) in purchases:\n",
    "        df_true.append([row,col,1])\n",
    "    else:\n",
    "        df_true.append([row,col,0])\n",
    "df_true = pd.DataFrame(data=df_true,columns=[USER, ITEM, RATING])\n",
    "df_true.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.160520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.017408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5451</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  prediction\n",
       "0       0       0   -0.160520\n",
       "1     437       0   -0.017408\n",
       "2    5451       0    0.066711"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = []\n",
    "y_hat = y_hat.todok()\n",
    "rows,cols = y_hat.nonzero()\n",
    "for row,col in zip(rows,cols):\n",
    "    df_pred.append([row,col,y_hat[row,col]])\n",
    "df_pred = pd.DataFrame(data=df_pred,columns=[USER, ITEM, PREDICTION])\n",
    "df_pred.head(3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error: 1.310757711564404 (calculated using sparse matrix operations)\n",
      "Mean Square Error: 1.3107577562332153 (calculated using sklearn.metrics)\n",
      "Note: The smaller the better.\n"
     ]
    }
   ],
   "source": [
    "MSE_sparse = csc.sum(csc.power(y_hat-y,2))/y.nnz\n",
    "MSE = mean_squared_error(y_nz,y_hat_nz)\n",
    "print(f\"Mean Square Error: {MSE_sparse} (calculated using sparse matrix operations)\")\n",
    "print(f\"Mean Square Error: {MSE} (calculated using sklearn.metrics)\")\n",
    "print('Note: The smaller the better.')\n",
    "log[\"MSE\"]=MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error: 1.144883274209386 (calculated using sparse matrix operations)\n",
      "Root Mean Square Error: 1.1448832750320435 (calculated using sklearn.metrics)\n",
      "Root Mean Square Error: 1.150347892413276 (calculated using MS Evaluation method)\n",
      "Note: The smaller the better.\n"
     ]
    }
   ],
   "source": [
    "RMSE = np.sqrt(MSE)\n",
    "RMSE_sparse = np.sqrt(MSE_sparse)\n",
    "print(f\"Root Mean Square Error: {RMSE_sparse} (calculated using sparse matrix operations)\")\n",
    "print(f\"Root Mean Square Error: {RMSE} (calculated using sklearn.metrics)\")\n",
    "print(f\"Root Mean Square Error: {rmse(df_true,df_pred)} (calculated using MS Evaluation method)\")\n",
    "print('Note: The smaller the better.')\n",
    "log[\"RMSE\"]=RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5893737381282198 (calculated using sparse matrix operations)\n",
      "Mean Absolute Error: 0.589373767375946 (calculated using sklearn.metrics)\n",
      "Note: The smaller the better.\n"
     ]
    }
   ],
   "source": [
    "MAE_sparse = csc.sum(abs(y_hat-y))/y.nnz\n",
    "MAE = mean_absolute_error(y_nz,y_hat_nz)\n",
    "print(f\"Mean Absolute Error: {MAE_sparse} (calculated using sparse matrix operations)\")\n",
    "print(f\"Mean Absolute Error: {MAE} (calculated using sklearn.metrics)\")\n",
    "print('Note: The smaller the better.')\n",
    "log[\"MAE\"]=MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination (R²): -17.556097329188866\n",
      "Note: The closer to 1 the better.\n"
     ]
    }
   ],
   "source": [
    "R2 = r2_score(y_nz,y_hat_nz)\n",
    "print(f\"Coefficient of determination (R\\u00B2): {R2}\")\n",
    "print(\"Note: The closer to 1 the better.\")\n",
    "log[\"R-squared\"]=R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: -16.636564254760742\n",
      "Note: The closer to 1 the better.\n"
     ]
    }
   ],
   "source": [
    "explained_variance = explained_variance_score(y_nz,y_hat_nz)\n",
    "print(f\"Explained variance: {explained_variance}\")\n",
    "print(\"Note: The closer to 1 the better.\")\n",
    "log[\"explained_variance\"]=explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arear Under Curve (AUC) - integral area under the receiver operating characteristic curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arear Under Curve (AUC): 0.5019304152889557\n",
      "Note: The closer to 1 the better. 0.5 indicates an uninformative classifier\n"
     ]
    }
   ],
   "source": [
    "# We must convert the predicted ratings into a [0, 1] scale.\n",
    "df_pred_bin = df_pred.copy()\n",
    "df_pred_bin[PREDICTION] = minmax_scale(df_pred_bin[PREDICTION].astype(float))\n",
    "auc_v = auc(df_true,df_pred_bin)\n",
    "print(f\"Arear Under Curve (AUC): {auc_v}\")\n",
    "print(\"Note: The closer to 1 the better. 0.5 indicates an uninformative classifier\")\n",
    "log[\"AUC\"]=auc_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic loss (logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic loss (logloss): 0.8080938278170747\n",
      "Note: The closer to 0 the better.\n"
     ]
    }
   ],
   "source": [
    "logisticloss = logloss(df_true,df_pred_bin)\n",
    "print(f\"Logistic loss (logloss): {logisticloss}\")\n",
    "print(\"Note: The closer to 0 the better.\")\n",
    "log[\"logloss\"]=logisticloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision @ K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @ 10: 0.34191752705560396\n",
      "Note: The closer to 1 the better.\n"
     ]
    }
   ],
   "source": [
    "prk = precision_at_k(df_true,df_pred)\n",
    "print(f\"Precision @ {DEFAULT_K}: {prk}\")\n",
    "print(\"Note: The closer to 1 the better.\")\n",
    "log[f\"precision-at-{DEFAULT_K}\"]=prk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall @ K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 10: 0.9668412602660089\n",
      "Note: The closer to 1 the better.\n"
     ]
    }
   ],
   "source": [
    "rk = recall_at_k(df_true,df_pred)\n",
    "print(f\"Recall @ {DEFAULT_K}: {rk}\")\n",
    "print(\"Note: The closer to 1 the better.\")\n",
    "log[f\"recall-at-{DEFAULT_K}\"]=rk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalized Discounted Cumulative Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized Discounted Cumulative Gain (nDCG@10): 1.0\n",
      "Note: The closer to 1 the better.\n"
     ]
    }
   ],
   "source": [
    "nDCG = ndcg_at_k(df_true,df_pred)\n",
    "print(f\"normalized Discounted Cumulative Gain (nDCG@{DEFAULT_K}): {nDCG}\")\n",
    "print(\"Note: The closer to 1 the better.\")\n",
    "log[f\"nDCG-at-{DEFAULT_K}\"]=nDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mAP (mean Average Precision) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean Average Precision (mAP@10): 0.9668412602660089\n",
      "Note: The closer to 1 the better.\n"
     ]
    }
   ],
   "source": [
    "mAP = map_at_k(df_true,df_pred)\n",
    "print(f\"mean Average Precision (mAP@{DEFAULT_K}): {mAP}\")\n",
    "print(\"Note: The closer to 1 the better.\")\n",
    "log[f\"nDCG-at-{DEFAULT_K}\"]=mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSE                    1.310758\n",
       "RMSE                   1.144883\n",
       "MAE                    0.589374\n",
       "R-squared            -17.556097\n",
       "explained_variance   -16.636564\n",
       "AUC                    0.501930\n",
       "logloss                0.808094\n",
       "precision-at-10        0.341918\n",
       "recall-at-10           0.966841\n",
       "nDCG-at-10             0.966841\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.to_csv(TEST_RESULTS_PATH, index = True, header=False)\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
