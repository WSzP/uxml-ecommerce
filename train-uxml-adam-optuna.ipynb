{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.5.0\n",
      "CUDA GPU 1: GeForce RTX 2080 Ti [Compute Capability: 7.5]\n",
      "PyTorch Lightning version: 0.7.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Logging enabled at DEBUG level.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "print(\"PyTorch version:\",torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "      print(f\"CUDA GPU {i+1}: {torch.cuda.get_device_name(i)} [Compute Capability: {torch.cuda.get_device_capability(0)[0]}.{torch.cuda.get_device_capability(0)[1]}]\")\n",
    "    device = torch.device('cuda')\n",
    "    kwargs = {'num_workers': 8, 'pin_memory': True}\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA GPU is not available. :(\")  \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "print (\"PyTorch Lightning version:\",pl.__version__)\n",
    "    \n",
    "import scipy.sparse as sp\n",
    "from argparse import Namespace\n",
    "\n",
    "from utilities.custom_lightning import CSVProfiler\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"Logging enabled at DEBUG level.\")\n",
    "\n",
    "from constants import (SEED, DATA_DIR, LOG_DIR, TRAIN_DATA_PATH, VAL_DATA_PATH, TEST_DATA_PATH)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = r'AdamOptunaUXML' \n",
    "SAVE_PATH = DATA_DIR+r'/'+NAME+r'.pt'\n",
    "PROFILE_PATH = LOG_DIR+'\\\\'+NAME+'\\\\profile.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interactions(Dataset):\n",
    "    \"\"\"\n",
    "    Create interactions matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, matrix):\n",
    "        self.matrix = matrix\n",
    "        self.n_users = self.matrix.shape[0]\n",
    "        self.n_items = self.matrix.shape[1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.matrix.row[index]\n",
    "        col = self.matrix.col[index]\n",
    "        val = self.matrix.data[index]\n",
    "        return (row, col), val\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.matrix.nnz\n",
    "    \n",
    "interaction = Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestingCallbacks(pl.Callback):\n",
    "    def on_test_start(self, trainer, pl_module):\n",
    "        global y_hat \n",
    "        y_hat = sp.dok_matrix((hparams.total_users, hparams.total_items), dtype=np.float32) \n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        logging.debug(f\"Non-zero values in prediction matrix: {y_hat.nnz:,}\")\n",
    "        sp.save_npz(DATA_DIR+NAME+r'-y_hat.npz',y_hat.tocoo())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamUXML(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(AdamUXML, self).__init__() \n",
    "        self.hparams = hparams\n",
    "        self.user_factors = nn.Embedding(hparams.total_users, hparams.n_factors, sparse=hparams.sparse)\n",
    "        self.item_factors = nn.Embedding(hparams.total_items, hparams.n_factors, sparse=hparams.sparse)\n",
    "        self.user_biases = nn.Embedding(hparams.total_users, 1, sparse=hparams.sparse)\n",
    "        self.item_biases = nn.Embedding(hparams.total_items, 1, sparse=hparams.sparse)\n",
    "        self.dropout = nn.Dropout(p=self.hparams.dropout_p)\n",
    "        \n",
    "    def forward(self, users, items):            \n",
    "        \n",
    "        user_factors_users = self.user_factors(users)\n",
    "        item_factors_items = self.item_factors(items)        \n",
    "        predictions = self.user_biases(users)\n",
    "        predictions += self.item_biases(items)\n",
    "        predictions += (self.dropout(user_factors_users) * self.dropout(item_factors_items)).sum(dim=1, keepdim=True)              \n",
    "        return predictions.squeeze()\n",
    "    \n",
    "    def MSELoss(self, logits, labels):\n",
    "        return nn.functional.mse_loss(logits, labels)\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        row, column = x\n",
    "        row = row.long()\n",
    "        column = column.long()\n",
    "        logits = self.forward(row,column)\n",
    "        loss = self.MSELoss(logits, y)\n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        row, column = x\n",
    "        row = row.long()\n",
    "        column = column.long()\n",
    "        logits = self.forward(row,column)                \n",
    "        loss = self.MSELoss(logits, y)\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        x, y = test_batch\n",
    "        row, column = x\n",
    "        row = row.long()\n",
    "        column = column.long()\n",
    "        logits = self.forward(row,column)                \n",
    "        loss = self.MSELoss(logits, y)        \n",
    "       \n",
    "        logits_array = logits.cpu().numpy()\n",
    "        r = row.cpu().numpy()\n",
    "        c = column.cpu().numpy()\n",
    "        for i in range(len(logits_array)):\n",
    "            y_hat[r[i],c[i]]=logits_array[i]      \n",
    "        \n",
    "        return {'test_loss': loss}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'MSE': avg_loss}\n",
    "        print(f\"Test Mean Squared Error (MSE): {avg_loss}\")                   \n",
    "        \n",
    "        return {'avg_test_loss': avg_loss, 'log': tensorboard_logs}\n",
    "      \n",
    "    def prepare_data(self):\n",
    "        self.train_dataset = sp.load_npz(TRAIN_DATA_PATH)\n",
    "        self.val_dataset = sp.load_npz(VAL_DATA_PATH)\n",
    "        self.test_dataset = sp.load_npz(TEST_DATA_PATH)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(interaction(self.train_dataset), batch_size=self.hparams.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(interaction(self.val_dataset), batch_size=self.hparams.batch_size, shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(interaction(self.test_dataset), batch_size=self.hparams.batch_size, shuffle=False)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                     lr=self.hparams.learning_rate,\n",
    "                                     betas=self.hparams.betas,\n",
    "                                     amsgrad=self.hparams.amsgrad)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uxm = sp.load_npz(TRAIN_DATA_PATH)\n",
    "total_users = uxm.shape[0]\n",
    "total_items = uxm.shape[1]\n",
    "del uxm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "INFO:lightning:Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "WARNING:lightning:No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "---------------------------------------\n",
      "0 | user_factors | Embedding | 3 M   \n",
      "1 | item_factors | Embedding | 895 K \n",
      "2 | user_biases  | Embedding | 177 K \n",
      "3 | item_biases  | Embedding | 44 K  \n",
      "4 | dropout      | Dropout   | 0     \n",
      "INFO:lightning:\n",
      "  | Name         | Type      | Params\n",
      "---------------------------------------\n",
      "0 | user_factors | Embedding | 3 M   \n",
      "1 | item_factors | Embedding | 895 K \n",
      "2 | user_biases  | Embedding | 177 K \n",
      "3 | item_biases  | Embedding | 44 K  \n",
      "4 | dropout      | Dropout   | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bfcdae36714a3791ffadc81fba9eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mProfiler Report\u001b[0m\n",
      "                   mean_duration  total_time\n",
      "on_train_start              0.02        0.02\n",
      "on_epoch_start              0.00        0.00\n",
      "get_train_batch             0.19        0.19\n",
      "on_batch_start              0.00        0.00\n",
      "model_forward               0.00        0.00\n",
      "model_backward              0.00        0.00\n",
      "on_after_backward           0.00        0.00\n",
      "optimizer_step              0.00        0.00\n",
      "on_batch_end                0.02        0.02\n",
      "on_epoch_end                0.00        0.00\n",
      "on_train_end                0.00        0.00\n",
      "\n",
      "Profiler output saved to: C:\\TensorLogs\\AdamOptunaUXML\\profile.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = Namespace(**{\n",
    "    'batch_size': 1024,\n",
    "    'learning_rate': 0.001,\n",
    "    'betas': (0.9, 0.999),\n",
    "    'n_factors': 20,\n",
    "    'dropout_p': 0.2, \n",
    "    'sparse': False,\n",
    "    'max_epochs': 5,\n",
    "    'amsgrad': False,\n",
    "    'total_users': total_users,\n",
    "    'total_items': total_items\n",
    "})\n",
    "\n",
    "profiler = CSVProfiler(output_path=PROFILE_PATH,verbose=True)\n",
    "logger = TensorBoardLogger(LOG_DIR, name=NAME)\n",
    "model = AdamUXML(hparams)\n",
    "trainer = pl.Trainer(max_epochs=hparams.max_epochs,\n",
    "                     benchmark=True,\n",
    "                     profiler=profiler,\n",
    "                     logger=logger,\n",
    "                     gpus=1,\n",
    "                     fast_dev_run=True,\n",
    "                     callbacks=[TestingCallbacks()])                \n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0500e7aa4e941c78026d7e0885aaf19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Non-zero values in prediction matrix: 1,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error (MSE): 21.35810089111328\n",
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'MSE': tensor(21.3581, device='cuda:0'),\n",
      " 'avg_test_loss': tensor(21.3581, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), SAVE_PATH)\n",
    "# loaded_model = AdamUXML(hparams)\n",
    "# loaded_model.load_state_dict(torch.load(SAVE_PATH))\n",
    "# loaded_model.eval()\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in loaded_model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", loaded_model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a5e3135c1eb4ad0b5a5a5a68b4aec9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "166d1dc4181e4085bf3f04305bcc6e64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch 1: 100%",
       "layout": "IPY_MODEL_eb815b8dca84448faf035c215f3c9df0",
       "max": 2,
       "style": "IPY_MODEL_0a5e3135c1eb4ad0b5a5a5a68b4aec9e",
       "value": 2
      }
     },
     "202dc2b45bd643e6be88a85c9eff0ea0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "info",
       "description": "Validating: 100%",
       "layout": "IPY_MODEL_44aee99c009046ba8887876f942adc6a",
       "max": 1,
       "style": "IPY_MODEL_bfe21060f0d14592ba68e5b0824ac5fa",
       "value": 1
      }
     },
     "38098b7bced848b2abe9490ffe8488f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "4479a182f5be429386ca764119abdad4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "44aee99c009046ba8887876f942adc6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "47e5151f4f9a40eb95d95802d05a423a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "4a49d288739d450eb1444ea1f2a777aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "5ed1f7b300834eee966e4cb5e8bbc257": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "74ba34cdd59949279ea493dddd37527a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5ed1f7b300834eee966e4cb5e8bbc257",
       "style": "IPY_MODEL_7ae6b07bd30441f49d8fdfb22bc92585",
       "value": " 2/2 [00:00&lt;00:00,  7.06it/s, loss=33.312, v_num=2]"
      }
     },
     "7ae6b07bd30441f49d8fdfb22bc92585": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8080a4de434a4840929074770d1b1234": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "94c60f46113e47bba39145e37cac1111": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dfd21846b60f4800b05d5b81f3feb451",
       "style": "IPY_MODEL_f4d511c43b054a4899e0d12aa11bfbb4",
       "value": " 1/1 [00:00&lt;00:00, 28.65it/s]"
      }
     },
     "9ff717df7dc041c39b8d93f3dd7b534a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8080a4de434a4840929074770d1b1234",
       "style": "IPY_MODEL_4479a182f5be429386ca764119abdad4",
       "value": " 1/1 [00:00&lt;00:00, 52.77it/s]"
      }
     },
     "b0500e7aa4e941c78026d7e0885aaf19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_dbbf3a71d5014cf2b455d54a562859c8",
        "IPY_MODEL_94c60f46113e47bba39145e37cac1111"
       ],
       "layout": "IPY_MODEL_cd6303d65957406ab8506a3bbd34a63f"
      }
     },
     "bfe21060f0d14592ba68e5b0824ac5fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "cd6303d65957406ab8506a3bbd34a63f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "dbbf3a71d5014cf2b455d54a562859c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Testing: 100%",
       "layout": "IPY_MODEL_f313584b91d24daf9c91a5df303f5de8",
       "max": 1,
       "style": "IPY_MODEL_47e5151f4f9a40eb95d95802d05a423a",
       "value": 1
      }
     },
     "dfd21846b60f4800b05d5b81f3feb451": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e2bfcdae36714a3791ffadc81fba9eaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_166d1dc4181e4085bf3f04305bcc6e64",
        "IPY_MODEL_74ba34cdd59949279ea493dddd37527a"
       ],
       "layout": "IPY_MODEL_38098b7bced848b2abe9490ffe8488f2"
      }
     },
     "eb815b8dca84448faf035c215f3c9df0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "f313584b91d24daf9c91a5df303f5de8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "f4d511c43b054a4899e0d12aa11bfbb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
